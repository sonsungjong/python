{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchain Expression Language\n",
    "\n",
    "- LCEL is that any two runnables can be \"chained\" together into sequences.\n",
    "\n",
    "1. Sequential Chain\n",
    "2. Parallel Chain\n",
    "3. Router Chain\n",
    "4. Chain Runnables\n",
    "5. Custom Chain (Runnable Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangSmith 환경변수 사용 (로컬에선 랭스미스말고 LangFuse 같은거 쓸 것)\n",
    "load_dotenv('./../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='llama3.2:1b', base_url='http://localhost:11434')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential LCEL Chain\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import(\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "# 랭체인 오라마 사용\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = \"llama3.2:1b\"\n",
    "\n",
    "llm = ChatOllama(base_url=base_url, model=model)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what I have to say:\n",
      "\n",
      "1. The sun is at the center of our solar system, making up most of its mass.\n",
      "2. It has eight planets: Mercury, Mars, Venus, Earth, Neptune, Uranus, Saturn, and Jupiter.\n",
      "3. Each planet has a unique shape due to its composition.\n",
      "4. The four inner planets (Mercury to Neptune) are rocky worlds with different atmospheres.\n",
      "5. Jupiter is the largest planet in our solar system, a gas giant with massive storms.\n"
     ]
    }
   ],
   "source": [
    "# 기존의 프롬프트 템플릿 사용법\n",
    "system = SystemMessagePromptTemplate.from_template('You are {school} teacher. You answer in short sentences.')\n",
    "question = HumanMessagePromptTemplate.from_template('Tell me about the {topics} in {points} points')\n",
    "\n",
    "messages = [system, question]\n",
    "template = ChatPromptTemplate(messages)\n",
    "\n",
    "question_template = template.invoke({'school':'primary', 'topics':'solar system','points':5})\n",
    "\n",
    "response = llm.invoke(question_template)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are five key points about the solar system:\n",
      "\n",
      "1. Our solar system consists of eight planets (Mercury to Neptune) with five other smaller bodies: dwarf planet Pluto, asteroids, comets, and moons.\n",
      "\n",
      "2. The four inner planets (Mercury to Mars) are rocky worlds, while the outer planets (Jupiter to Neptune) are gas giants with no solid surface.\n",
      "\n",
      "3. Jupiter is the largest planet in our solar system, with a massive size and strong gravitational pull that holds the other planets in their orbits.\n",
      "\n",
      "4. Venus is often called Earth's twin due to its similar size and mass, but it has a thick atmosphere that traps heat, making it extremely hot on the surface.\n",
      "\n",
      "5. Mars is a rocky world with a thin atmosphere, and NASA's Curiosity rover recently discovered evidence of ancient rivers and lakes, suggesting that Mars may have been habitable in the past.\n"
     ]
    }
   ],
   "source": [
    "# Sequential LCEL 사용법\n",
    "system = SystemMessagePromptTemplate.from_template('You are {school} teacher. You answer in short sentences.')\n",
    "question = HumanMessagePromptTemplate.from_template('Tell me about the {topics} in {points} points')\n",
    "\n",
    "messages = [system, question]\n",
    "template = ChatPromptTemplate(messages)\n",
    "\n",
    "# | 로 합친 것을 invoke\n",
    "chain = template | llm\n",
    "\n",
    "response = chain.invoke({'school':'primary', 'topics':'solar system','points':5})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a brief overview of the solar system:\n",
      "\n",
      "1. The sun is at the center, making up about 99% of the total mass.\n",
      "2. There are eight planets: Mercury, Mars, Venus, Earth, Neptune, Uranus, Saturn, and Jupiter.\n",
      "3. Each planet has its unique features, like Earth's atmosphere and Moon, which orbits it.\n",
      "4. The closest planet to the sun is Mercury, while the farthest is Neptune.\n",
      "5. Pluto was previously considered a planet but was reclassified as a dwarf planet in 2006 by the International Astronomical Union.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = template | llm | StrOutputParser()\n",
    "response = chain.invoke({'school':'primary','topics':'solar system','points':5})\n",
    "print(response)             # content 사용을 하지 않음 (str만 남음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has some complex vocabulary and abstract concepts, such as \"unique features\", \"atmosphere\", and \"dwarf planet\", making it challenging for non-experts to grasp.\n"
     ]
    }
   ],
   "source": [
    "### Chaining Runnables (Chain Multiple Runnables)\n",
    "# 위에서 받은 답변을 요약해달라고 하기\n",
    "\n",
    "analysis_prompt = ChatPromptTemplate.from_template('''analyze the following text: {response}\n",
    "                                                   You need tell me that how difficult it is to understand.\n",
    "                                                   Answer in one sentence only.\n",
    "                                                    ''')\n",
    "fact_check_chain = analysis_prompt | llm | StrOutputParser()\n",
    "output = fact_check_chain.invoke({'response':response})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is moderately clear, but may be challenging for non-expert readers with limited knowledge of astronomy or the solar system's classification.\n"
     ]
    }
   ],
   "source": [
    "composed_chain = {\"response\":chain} | analysis_prompt | llm | StrOutputParser()\n",
    "\n",
    "output = composed_chain.invoke({'school':'phd', 'topics':'solar system','points':5})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sun is at the center of our solar system.\n",
      "\n",
      "There are eight planets, two dwarf planets, and five other smaller bodies orbiting around it: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.\n"
     ]
    }
   ],
   "source": [
    "### Parallel LCEL Chain\n",
    "# run multiple runnables in parallel.\n",
    "# return dict\n",
    "\n",
    "system = SystemMessagePromptTemplate.from_template('You are {school} teacher. You answer in short sentences.')\n",
    "question = HumanMessagePromptTemplate.from_template('Tell me about the {topics} in {points} points')\n",
    "message = [system, question]\n",
    "template = ChatPromptTemplate(message)\n",
    "\n",
    "fact_chain = template | llm | StrOutputParser()\n",
    "# output = fact_chain.invoke({'school':'primary','topics':'solar system','points':2})\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a short poem:\n",
      "\n",
      "The sun at center, planets sway,\n",
      "Orbiting it, each one in its way.\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessagePromptTemplate.from_template('Write a poem on {topics} in {sentences} lines')\n",
    "message = [system, question]\n",
    "template = ChatPromptTemplate(message)\n",
    "\n",
    "poem_chain = template | llm | StrOutputParser()\n",
    "# output = poem_chain.invoke({'school':'primary','topics':'solar system','sentences':2})\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = HumanMessagePromptTemplate.from_template('Explain the {topics} in {sentences} lines in {language}')\n",
    "message = [system, question]\n",
    "template = ChatPromptTemplate(message)\n",
    "\n",
    "third_chain = template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what you need to know about the solar system:\n",
      "\n",
      "• The Sun is at the center of our solar system, which includes eight planets and many smaller objects like moons, asteroids, and comets.\n",
      "• The four outer planets (Jupiter, Saturn, Uranus, and Neptune) are gas giants with no solid surface, while Mercury and Venus are rocky planets with solid surfaces.\n",
      "\n",
      "\n",
      "\n",
      "The sun is at the center, \n",
      "Planets orbit around it with care.\n",
      "\n",
      "\n",
      "\n",
      "우주의 반지름이 약 149.6만 km이며, 가장 큰 우주체는 주성 planets (mercury, mars, saturn, jupiter)이다. 우주의 중력의 강さ가 varies하며, farthest planet은 Neptune이고, farthest distance에서 관측할 수 있는 farthest planet은 Pluto이다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain = RunnableParallel(fact=fact_chain, poem=poem_chain, korean=third_chain)\n",
    "\n",
    "output = chain.invoke({'school':'primary','topics':'solar system', 'points':2, 'sentences':2, 'language':'Korean'})\n",
    "\n",
    "print(output['fact'])\n",
    "print('\\n\\n')\n",
    "print(output['poem'])\n",
    "print('\\n\\n')\n",
    "print(output['korean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### chain router\n",
    "prompt = \"\"\"\n",
    "Given the user review below, classify it as either being about `Positive` or `Negative`.\n",
    "Do not respond with more than one word.\n",
    "\n",
    "Review: {review}\n",
    "Classification:\n",
    "\"\"\"\n",
    "\n",
    "template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "chain = template | llm | StrOutputParser()\n",
    "\n",
    "# review = \"Thank you so much for providing such a great platform for learning. I am really happy with the service.\"\n",
    "# review = \"I am not happy with the service. It is not good.\"\n",
    "review = \"보기에는 조촐해보였지만 성능은 확실합니다.\"\n",
    "\n",
    "chain.invoke({'review':review})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_prompt = \"\"\"\n",
    "You are expert in writing reply for positive reviews.\n",
    "You need to encourage the user to share their experience on social media.\n",
    "Review: {review}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "positive_template = ChatPromptTemplate.from_template(positive_prompt)\n",
    "positive_chain = positive_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_prompt = \"\"\"\n",
    "You are expert in writing reply for negative reviews.\n",
    "You need first to apologize for the inconvenience caused to the user.\n",
    "You need to encourage the user to share their concern on following Email:'uu@kk.com'.\n",
    "Review: {review}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "negative_template = ChatPromptTemplate.from_template(negative_prompt)\n",
    "negative_chain = negative_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rout(info):\n",
    "    if 'positive' in info['sentiment'].lower():\n",
    "        return positive_chain\n",
    "    else:\n",
    "        return negative_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['review'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['review'], input_types={}, partial_variables={}, template=\"\\nYou are expert in writing reply for negative reviews.\\nYou need first to apologize for the inconvenience caused to the user.\\nYou need to encourage the user to share their concern on following Email:'uu@kk.com'.\\nReview: {review}\\nAnswer:\\n\"), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:1b', base_url='http://localhost:11434')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rout({'sentiment':'negative'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "full_chain = {'sentiment':chain, 'review': lambda x: x['review']} | RunnableLambda(rout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a potential response:\n",
      "\n",
      "\"I'm so sorry to hear that your experience with our service didn't meet your expectations. We apologize for any inconvenience or frustration this has caused, and we're truly sorry that you didn't find our services satisfactory.\n",
      "\n",
      "We take all complaints seriously and would like to make things right. Please know that we're actively working on improving our services, and we value your feedback as an important part of this process. If there's anything specific you'd like to share or if you have any further concerns, I'd be more than happy to listen and help in any way I can.\n",
      "\n",
      "If you need assistance with a refund or compensation for your time, please don't hesitate to reach out to us at [your email address]. We're committed to providing the best possible service, and we appreciate your input in helping us improve. You can reply to this message directly from our website, and we'll get back to you promptly.\n",
      "\n",
      "Thank you for sharing your feedback with us. We hope to have the opportunity to serve you better in the future.\"\n"
     ]
    }
   ],
   "source": [
    "# review = \"Thank you so much for providing such a great platform for learning. I am really happy with the service.\"\n",
    "review = \"I am not happy with the service. It is not good.\"\n",
    "\n",
    "output = full_chain.invoke({'review':review})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
