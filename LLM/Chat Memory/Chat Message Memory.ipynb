{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Message Memory\n",
    "\n",
    "session id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lang Smith\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Sungjong Son, thank you for reaching out. It's great to connect with someone from the DevCom team. How can I assist you today?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import (SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, PromptTemplate)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:1b'\n",
    "\n",
    "llm = ChatOllama(base_url=base_url, model=model)\n",
    "\n",
    "template = ChatPromptTemplate.from_template(\"{prompt}\")\n",
    "chain = template | llm | StrOutputParser()\n",
    "\n",
    "about = \"My name is Sungjong Son. I work for DevCom\"\n",
    "chain.invoke({'prompt':about})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runnable with Message History (메시지 내용 기억시키기)\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import SQLChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id):\n",
    "    return SQLChatMessageHistory(session_id, \"sqlite:///chat_history.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable_with_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_1832\\2599343957.py:2: LangChainDeprecationWarning: `connection_string` was deprecated in LangChain 0.2.2 and will be removed in 1.0. Use connection instead.\n",
      "  history = get_session_history(user_id)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 'sungjong'\n",
    "history = get_session_history(user_id)\n",
    "\n",
    "history.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a more polished version:\\n\\n```\\n[HumanMessage(\\n    content='My name is Sungjong Son. I work for DevCom',\\n    additional_kwargs={'context': 'devcom.com', 'language': 'eng'},\\n    response_metadata={}\\n)]\\n```\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke([HumanMessage(content=about)], config={'configurable': {'session_id':user_id}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It seems like you\\'re using the AIMessage class from the python-aiml library, which is used for building conversational interfaces. \\n\\nHere\\'s an example of how you can use this class:\\n\\n```python\\nfrom aiml import HumanMessage\\n\\ndef main():\\n    # Define your message content\\n    message = \"\"\"\\n    Hi, I\\'m Sungjong Son.\\n    My work is at DevCom.\\n    \"\"\"\\n\\n    # Create a HumanMessage object\\n    human_message = HumanMessage(message)\\n\\n    # Print the response metadata\\n    print(\"Response Metadata:\")\\n    for key, value in human_message.response_metadata.items():\\n        print(f\"{key}: {value}\")\\n\\n    # Send the message and get the response\\n    response = human_message.send()\\n\\n    # Parse the response\\n    parsed_response = HumanMessage(parsed_response).parse_response()\\n\\n    # Print the response text\\n    print(\"\\\\nResponse Text:\")\\n    for key, value in parsed_response.items():\\n        print(f\"{key}: {value}\")\\n\\nif __name__ == \"__main__\":\\n    main()\\n```\\n\\nThis code will create a conversational interface with your message content and then respond to it. It prints out the response metadata and text, which includes any additional context or information that was provided during the conversation.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_with_history.invoke([HumanMessage(content=\"What is my name?\")], config={'configurable': {'session_id':user_id}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message history with Dictionary Like Inputs\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import (SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate, PromptTemplate, MessagesPlaceholder)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "system = SystemMessagePromptTemplate.from_template(\"You are helpful assistant.\")\n",
    "human = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "\n",
    "messages = [system, MessagesPlaceholder(variable_name='history'), human]\n",
    "\n",
    "prompt = ChatPromptTemplate(messages=messages)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "runnable_with_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key='input', history_messages_key='history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_llm(session_id, input):\n",
    "    output = runnable_with_history.invoke({'input':input}, config={'configurable':{'session_id':session_id}})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You work in DevCom, which means you're likely involved in the development and commissioning of computer systems and software. Is there anything on your mind that you'd like to discuss or ask about in relation to your role at DevCom?\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = \"son\"\n",
    "chat_with_llm(user_id, \"My name is Sungjong Son. I work for DevCom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I remember! Your name is Sungjong Son, and you work for DevCom.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_with_llm(user_id, \"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
