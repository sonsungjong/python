{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv('./../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import (SystemMessagePromptTemplate, HumanMessagePromptTemplate, PromptTemplate, ChatPromptTemplate)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from PIL import Image\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# 모델 불러오기\n",
    "ollama_model = 'granite3.2-vision'              # ollama pull granite3.2-vision\n",
    "# ollama_model = 'llava:7b'\n",
    "# ollama_model = 'llama3.2-vision:11b'\n",
    "ollama_url = 'http://localhost:11434'\n",
    "\n",
    "llm = ChatOllama(model=ollama_model, base_url=ollama_url)\n",
    "\n",
    "# 이미지 인코딩 (Base64 변환)\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# 이미지 다운로드    \n",
    "# image_url = \"\"\n",
    "# response = requests.get(image_url)\n",
    "# image = Image.open(BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "You are helpful AI assistant who answer user question based on the provided image.\n",
    "\"\"\")\n",
    "\n",
    "question_format = \"\"\"\n",
    "Answer user question based on the provided image ONLY! If you do not know the answer, just say \"I do not know\".\n",
    "### Image:\n",
    "{image}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\"\"\"\n",
    "\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(question_format)\n",
    "\n",
    "messages = [system_prompt, human_prompt]\n",
    "template = ChatPromptTemplate(messages)\n",
    "\n",
    "# 체인 생성\n",
    "qna_chain = template | llm | StrOutputParser()\n",
    "\n",
    "# 함수 제작\n",
    "def ask_llm(image_base64, question):\n",
    "    return qna_chain.invoke({'image':image_base64, 'question':question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The image appears to be a large, complex string of characters that does not form any recognizable text or pattern. It seems to be a random assortment of letters and symbols without any discernible meaning or structure.\n"
     ]
    }
   ],
   "source": [
    "# 이미지를 Base64 로 변환\n",
    "image_path = \"app_icon_p80.png\"\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "# 이미지를 넣어서 질문하기\n",
    "response = ask_llm(image_base64, \"Summarize the contents of this image.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can analyze the image, but I must point out that it appears to be a corrupted or encoded image. The text you provided seems to be a binary representation of an image file, possibly a PNG file.\n",
      "\n",
      "After decoding the binary data, I found that it's actually a base64-encoded string, which is a common way to represent binary data in text format. However, upon further analysis, I realized that this specific encoded string doesn't correspond to any valid or recognizable image.\n",
      "\n",
      "If you could provide more context about where you got this image from or what kind of image it should be representing, I might be able to help you better. Alternatively, if you can share the original image file or a link to it, I'll do my best to analyze it for you.\n"
     ]
    }
   ],
   "source": [
    "# 랭체인 없이 해보기\n",
    "import ollama\n",
    "import base64\n",
    "\n",
    "# 이미지를 Base64 로 변환\n",
    "image_path = \"img_korean.png\"\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "# 🔹 Ollama에 멀티모달 프롬프트 전달 (Base64 문자열을 직접 포함)\n",
    "prompt = f\"\"\"\n",
    "I have provided an image in Base64 format below. Analyze this image and answer my question.\n",
    "\n",
    "Image (Base64):\n",
    "{image_base64}\n",
    "\n",
    "Question:\n",
    "Analyze this image.\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    # model=\"granite3.2-vision\",\n",
    "    # model=\"llava:7b\",\n",
    "    model=\"llama3.2-vision:11b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 🔹 결과 출력\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
