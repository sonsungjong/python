{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv('./../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import (SystemMessagePromptTemplate, HumanMessagePromptTemplate, PromptTemplate, ChatPromptTemplate)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from PIL import Image\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "ollama_model = 'granite3.2-vision'              # ollama pull granite3.2-vision\n",
    "# ollama_model = 'llava:7b'\n",
    "# ollama_model = 'llama3.2-vision:11b'\n",
    "ollama_url = 'http://localhost:11434'\n",
    "\n",
    "llm = ChatOllama(model=ollama_model, base_url=ollama_url)\n",
    "\n",
    "# ì´ë¯¸ì§€ ì¸ì½”ë”© (Base64 ë³€í™˜)\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ    \n",
    "# image_url = \"\"\n",
    "# response = requests.get(image_url)\n",
    "# image = Image.open(BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessagePromptTemplate.from_template(\"\"\"\n",
    "You are helpful AI assistant who answer user question based on the provided image.\n",
    "\"\"\")\n",
    "\n",
    "question_format = \"\"\"\n",
    "Answer user question based on the provided image ONLY! If you do not know the answer, just say \"I do not know\".\n",
    "### Image:\n",
    "{image}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\"\"\"\n",
    "\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(question_format)\n",
    "\n",
    "messages = [system_prompt, human_prompt]\n",
    "template = ChatPromptTemplate(messages)\n",
    "\n",
    "# ì²´ì¸ ìƒì„±\n",
    "qna_chain = template | llm | StrOutputParser()\n",
    "\n",
    "# í•¨ìˆ˜ ì œì‘\n",
    "def ask_llm(image_base64, question):\n",
    "    return qna_chain.invoke({'image':image_base64, 'question':question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The image appears to be a large, complex string of characters that does not form any recognizable text or pattern. It seems to be a random assortment of letters and symbols without any discernible meaning or structure.\n"
     ]
    }
   ],
   "source": [
    "# ì´ë¯¸ì§€ë¥¼ Base64 ë¡œ ë³€í™˜\n",
    "image_path = \"app_icon_p80.png\"\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "# ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì„œ ì§ˆë¬¸í•˜ê¸°\n",
    "response = ask_llm(image_base64, \"Summarize the contents of this image.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can analyze the image, but I must point out that it appears to be a corrupted or encoded image. The text you provided seems to be a binary representation of an image file, possibly a PNG file.\n",
      "\n",
      "After decoding the binary data, I found that it's actually a base64-encoded string, which is a common way to represent binary data in text format. However, upon further analysis, I realized that this specific encoded string doesn't correspond to any valid or recognizable image.\n",
      "\n",
      "If you could provide more context about where you got this image from or what kind of image it should be representing, I might be able to help you better. Alternatively, if you can share the original image file or a link to it, I'll do my best to analyze it for you.\n"
     ]
    }
   ],
   "source": [
    "# ë­ì²´ì¸ ì—†ì´ í•´ë³´ê¸°\n",
    "import ollama\n",
    "import base64\n",
    "\n",
    "# ì´ë¯¸ì§€ë¥¼ Base64 ë¡œ ë³€í™˜\n",
    "image_path = \"img_korean.png\"\n",
    "image_base64 = encode_image_to_base64(image_path)\n",
    "\n",
    "# ğŸ”¹ Ollamaì— ë©€í‹°ëª¨ë‹¬ í”„ë¡¬í”„íŠ¸ ì „ë‹¬ (Base64 ë¬¸ìì—´ì„ ì§ì ‘ í¬í•¨)\n",
    "prompt = f\"\"\"\n",
    "I have provided an image in Base64 format below. Analyze this image and answer my question.\n",
    "\n",
    "Image (Base64):\n",
    "{image_base64}\n",
    "\n",
    "Question:\n",
    "Analyze this image.\n",
    "\"\"\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    # model=\"granite3.2-vision\",\n",
    "    # model=\"llava:7b\",\n",
    "    model=\"llama3.2-vision:11b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# ğŸ”¹ ê²°ê³¼ ì¶œë ¥\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
