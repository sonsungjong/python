{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25480030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEmbeddings\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import display, Image\n",
    "from langchain.schema import Document\n",
    "from langchain import hub\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableConfig, RunnablePassthrough, RunnableLambda\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a64ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "# os.environ[\"HF_HOME\"] = \"./cache/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f135d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools import TavilySearch\n",
    "\n",
    "tools = [TavilySearch(max_results=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ac059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer in Korean.\"\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{messages}\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0)\n",
    "\n",
    "# ReAct 에이전트 생성\n",
    "agent_executor = create_react_agent(llm, tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f40a437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='랭체인 한국어 튜토리얼에 대해서 설명해줘', additional_kwargs={}, response_metadata={}, id='e5af4857-e29f-4744-95d5-02b7fbd83f85'),\n",
       "  AIMessage(content='좋아요. 랭체인(LangChain) 한국어 튜토리얼에 대해 개괄적으로 설명해 드릴게요. 아래 내용은 한국어로 LLM 기반 애플리케이션을 처음부터 차근차근 만들어 보는 것을 목표로 한 초안 구성입니다. 필요에 따라 깊이와 속도를 조정해 드릴 수 있어요.\\n\\n1) 랭체인이란?\\n- 랭체인은 LLM(대형 언어 모델)을 활용한 애플리케이션 개발을 쉽게 해주는 파이썬 라이브러리예요.\\n- 주요 구성 요소: 프롬프트 관리(prompts), 체인(chains), 에이전트(agents), 도구(tools), 메모리(memory), 벡터 저장소(vector stores) 등.\\n- 한국어 튜토리얼의 포커스: 한국어 데이터로도 프롬프트를 다루고, 한국어 환경에서의 디버깅·실전 운용 방법을 중점적으로 다루는 것.\\n\\n2) 한국어 튜토리얼의 목표\\n- 한국어로 LLM 애플리케이션을 설계하고 구현하는 기본 역량 확보\\n- 프롬프트 템플릿 작성과 체인 구성의 흐름 이해\\n- 메모리와 에이전트를 활용한 대화 흐름 관리\\n- 벡터 저장소를 이용한 지식 기반 질의응답 구현\\n- 한국어 데이터의 특성(토큰화, 형태소, 다의어 처리 등)에 대한 실무 팁 습득\\n- 배포 전 점검 항목과 비용 관리의 기본 이해\\n\\n3) 추천 학습 순서\\n- 환경 구성과 기초 다지기\\n  - 파이썬 설치, 가상환경 만들기, langchain 및 필요한 패키지 설치\\n  - 기본적인 텍스트 데이터 처리 방법 복습(한국어 토큰화 예시)\\n- 프롬프트 템플릿 이해\\n  - PromptTemplate의 역할, 프롬프트 파라미터 만들기\\n  - 한국어 프롬프트 설계 시 주의점(공백, 한글 인코딩, 톤)\\n- LLMChain으로 간단한 체인 만들기\\n  - 하나의 LLM과 하나의 프롬프트로 질의응답 체인 구성\\n  - 입력-출력 흐름 확인\\n- 체인 확장\\n  - SequentialChain으로 여러 단계 연결하기\\n  - 조건부 흐름, 간단한 의사결정 로직 넣기\\n- 메모리와 대화 상태 관리\\n  - ConversationBufferMemory 등으로 대화 맥락 유지\\n  - 사용자와의 이전 대화를 기억해주는 간단한 예제\\n- 에이전트와 도구\\n  - 에이전트의 개념 이해\\n  - 도구(예: 웹 검색, 계산기, 코드 실행 등)와의 연동 기본\\n- 벡터 저장소와 지식 기반 질의응답\\n  - FAISS/Chroma 등 벡터 DB와 문서 인덱싱\\n  - 문서 요약 + 질의응답 파이프라인 구성\\n- 실전 예제\\n  - 한국어 문서 요약 + Q&A 챗봇\\n  - 다중 소스(문서, 웹) 연결 질의응답\\n- 디버깅, 성능 최적화, 배포\\n  - 입력 길이 관리, 토큰 수 최적화\\n  - 비용 예측과 모니터링 기본\\n  - 간단한 배포 아이디어(like API 엔드포인트)\\n\\n4) 한국어 튜토리얼에서 다루면 좋은 구체 내용\\n- 프롬프트 설계에 대한 베스트 프랙티스\\n  - 명확한 질문 형식, 기대되는 출력 형식(예: 요약, 목록, 코드 스니펫)\\n  - 한국어 특유의 표현 방식 다루기(경어, 존댓말, 상황별 톤 조절)\\n- 한국어 데이터 이슈\\n  - 한글 토큰화의 영향, 형태소 분석의 필요성\\n  - 다의어나 문화적 맥락 처리 방법\\n- 실습 예제 아이디어\\n  - 한국어 문서 요약 도우미\\n  - 국내 기사/블로그 기반의 Q&A 챗봇\\n  - 법률/의료 등 도메인별 간단한 도구형 에이전트\\n- 안전성 및 프라이버시\\n  - 민감 정보 다루기 시나리오 주의점\\n  - 로그 저장 정책과 데이터 익명화 기본\\n\\n5) 자주 쓰는 한국어 튜토리얼 포인트\\n- 한국어 자료가 영어 자료보다 적은 편이므로, 공식 문서를 기본 축으로 삼되 한국어 블로그나 영상으로 보충\\n- 예제는 한국어 데이터를 직접 다루는 방식으로 따라하기\\n- 코드 예시는 간단한 회전법으로 이해하고, 점차 확장하는 방식으로 진행\\n\\n6) 강화 학습/확장 아이디어\\n- 다중 출처 지식통합 챗봇: 문서 저장소 + 웹에서의 실시간 정보 검색 결합\\n- 대화형 도구를 활용한 업무 자동화 봇(날짜 확인, 일정 관리 등)\\n- 한국어 데이터 특성에 맞춘 평가 지표 설계(응답 품질, 중의성 해소 여부)\\n\\n7) 시작 방법과 활용 팁\\n- 시작은 간단한 예제로 시작하고 점차 확장하기\\n- 공식 문서를 먼저 따라 해보고, 한국어 주석/주석 달기\\n- 버전 차이에 주의하고, 특정 버전에서의 API 차이를 사전에 확인하기\\n- 자주 묻는 질문에 대비한 체크리스트 만들기\\n\\n8) 원하시면 구체적인 한국어 튜토리얼 초안 제안\\n- 학습 대상자에 따라 초급용, 중급용, 실전 프로젝트형으로 구조 조정 가능\\n- 예제 코드 스니펫, 실습 파일(데모 데이터, 노트북 템플릿) 포함한 커리큘럼으로 구성해 드릴 수 있어요\\n\\n원하시는 방향을 알려주시면\\n- 대상자 레벨(초보자/중급자)\\n- 튜토리얼 길이(예: 1주차/4주차/8주차 등)\\n- 선호하는 구성(읽기자료+실습노트+퀴즈/프로젝트 중심)\\n에 맞춰 한국어 튜토리얼 초안 구조와 구체적인 강의안, 실습 파일 목록까지 상세하게 구성해 드리겠습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2939, 'prompt_tokens': 240, 'total_tokens': 3179, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1472, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CFuINR74wm1tnzB8VQZA6DGvzPWDQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8b962e30-00d7-4e8f-b1e8-3d7e4d307506-0', usage_metadata={'input_tokens': 240, 'output_tokens': 2939, 'total_tokens': 3179, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1472}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\"messages\":[(\"user\", \"랭체인 한국어 튜토리얼에 대해서 설명해줘\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ea73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e02eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계 : 문서 로드\n",
    "loader = PyMuPDFLoader(\"SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2단계 : 문서 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# 3단계 : 임베딩\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = \"BAAI/bge-m3\",\n",
    "    model_kwargs = {\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "# 4단계 : 벡터스토어 저장/불러오기\n",
    "try:\n",
    "    vectorstore = FAISS.load_local(\n",
    "        folder_path=\"faiss_db\",\n",
    "        index_name=\"faiss_index\",\n",
    "        embeddings=hf_embeddings,\n",
    "        allow_dangerous_deserialization=True,\n",
    "    )\n",
    "except:\n",
    "    vectorstore = FAISS.from_documents(split_documents, hf_embeddings)\n",
    "    vectorstore.save_local(\"faiss_db\", \"faiss_index\")\n",
    "\n",
    "# vectorstore.add_documents(new_split_documents)\n",
    "# vectorstore.save_local(\"faiss_db\", \"faiss_index\")\n",
    "\n",
    "# 5단계 : 검색기 Retriever 생성\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 6단계 : 프롬프트\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "You must include `page` number in your answer.\n",
    "Answer in Korean.\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Context:\n",
    "{context}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# 7단계 : LLM 생성\n",
    "# llm = ChatOpenAI(model_name=\"gpt-5-nano\", temperature=0, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "llm = ChatOllama(model=\"llama3.2:4b\", temperature=0, base_url=\"http://localhost:11434\")\n",
    "\n",
    "# 8단계 : chain 생성\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(\n",
    "        f\"[page {d.metadata.get('page', 0) + 1}] {d.page_content}\" for d in docs\n",
    "    )\n",
    "\n",
    "chain = (\n",
    "    {\"context\":retriever | RunnableLambda(format_docs), \"question\":RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9beb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c47a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a29ae8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a3169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97207929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110fc9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5aab91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c53ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7561e0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06399a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb233a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877701ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f2b57a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
