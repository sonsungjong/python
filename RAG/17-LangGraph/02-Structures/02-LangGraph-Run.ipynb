{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea8c24c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기본적인 Naive RAG -> 조건부엣지 검사 -> 웹 검색 -> 쿼리 재작성\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, TypedDict, List\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec0b2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭그래프에서는 Retriever 와 Chain 을 따로 생성해서 다른 노드에 위치시킨다\n",
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "pdf = PDFRetrievalChain([\"SPRI_AI_Brief_2023년12월호_F.pdf\"]).create_chain()\n",
    "\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc74771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='3e4c95a5-d6b8-4cb9-b213-3a372b9829b8', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 13, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화\\nKEY Contents\\nn 구글이 앤스로픽에 최대 20억 달러 투자에 합의하고 5억 달러를 우선 투자했으며, 앤스로픽은\\n구글과 클라우드 서비스 사용 계약도 체결\\nn 3대 클라우드 사업자인 구글, 마이크로소프트, 아마존은 차세대 AI 모델의 대표 기업인\\n앤스로픽 및 오픈AI와 협력을 확대하는 추세\\n£구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공'),\n",
       " Document(id='50fc6ba3-9966-459c-bd59-4c40d2b2659e', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 13, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='£구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\\nn 구글이 2023년 10월 27일 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 중 5억\\n달러를 우선 투자하고 향후 15억 달러를 추가로 투자할 방침\\n∙ 구글은 2023년 2월 앤스로픽에 이미 5억 5,000만 달러를 투자한 바 있으며, 아마존도 지난 9월\\n앤스로픽에 최대 40억 달러의 투자 계획을 공개\\n∙ 한편, 2023년 11월 8일 블룸버그 보도에 따르면 앤스로픽은 구글의 클라우드 서비스 사용을 위해\\n4년간 30억 달러 규모의 계약을 체결'),\n",
       " Document(id='162a69ad-a936-43bd-ae80-d426dc94f71b', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 13, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='4년간 30억 달러 규모의 계약을 체결\\n∙ 오픈AI 창업자 그룹의 일원이었던 다리오(Dario Amodei)와 다니엘라 아모데이(Daniela Amodei)\\n남매가 2021년 설립한 앤스로픽은 챗GPT의 대항마 ‘클로드(Claude)’ LLM을 개발\\nn 아마존과 구글의 앤스로픽 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인 오픈\\nAI와 협력을 확대\\n∙ 마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 더해 2023년 1월 추가로 100억 달러를'),\n",
       " Document(id='93abe607-e9cf-436a-8c74-6801335ef88f', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 13, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='투자하기로 하면서 오픈AI의 지분 49%를 확보했으며, 오픈AI는 마이크로소프트의 애저(Azure)\\n클라우드 플랫폼을 사용해 AI 모델을 훈련\\n£구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\\nn 구글은 수익률이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를\\n통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자를 지속\\n∙ 구글은 앤스로픽 외에도 AI 동영상 제작 도구를 개발하는 런웨이(Runway)와 오픈소스 소프트웨어\\n기업 허깅 페이스(Hugging Face)에도 투자'),\n",
       " Document(id='e7a68a7c-ddd6-448d-bdf6-8e399a427467', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 1, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='2. 기업/산업\\n▹ 미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성································7\\n▹ 코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개 ·······································8\\n▹ 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································9'),\n",
       " Document(id='68340f18-9557-4f6a-8b19-5eb162fb2bad', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 9, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\\n미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성\\nKEY Contents\\nn 구글, 앤스로픽, 마이크로소프트, 오픈AI가 참여하는 프런티어 모델 포럼이 자선단체와 함께 AI\\n안전 연구를 위한 1,000만 달러 규모의 AI 안전 기금을 조성\\nn 프런티어 모델 포럼은 AI 모델의 취약점을 발견하고 검증하는 레드팀 활동을 지원하기 위한\\n모델 평가 기법 개발에 자금을 중점 지원할 계획'),\n",
       " Document(id='d555f340-2b6b-4720-ae52-ee84e67b2386', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 9, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='모델 평가 기법 개발에 자금을 중점 지원할 계획\\n£프런티어 모델 포럼, 자선단체와 함께 AI 안전 연구를 위한 기금 조성\\nn 구글, 앤스로픽, 마이크로소프트, 오픈AI가 출범한 프런티어 모델 포럼이 2023년 10월 25일 AI 안전\\n연구를 위한 기금을 조성한다고 발표\\n∙ 참여사들은 맥거번 재단(Patrick J. McGovern Foundation), 데이비드 앤 루실 패커드 재단(The\\nDavid and Lucile Packard Foundation) 등의 자선단체와 함께 AI 안전 연구를 위한 기금에'),\n",
       " Document(id='6b1d8db9-de39-497a-98d1-c7a21483dc4e', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 1, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\\n▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\\n▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12'),\n",
       " Document(id='6d6d665f-e026-401b-9d03-41db4ef7a8e1', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 9, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='1,000만 달러 이상을 기부\\n∙ 또한 신기술의 거버넌스와 안전 분야에서 전문성을 갖춘 브루킹스 연구소 출신의 크리스 메서롤(Chris\\nMeserole)을 포럼의 상무이사로 임명\\nn 최근 AI 기술이 급속히 발전하면서 AI 안전에 관한 연구가 부족한 시점에, 포럼은 이러한 격차를 해소\\n하기 위해 AI 안전 기금을 조성\\n∙ 참여사들은 지난 7월 백악관 주재의 AI 안전 서약에서 외부자의 AI 시스템 취약점 발견과 신고를\\n촉진하기로 약속했으며, 약속을 이행하기 위해 기금을 활용해 외부 연구집단의 AI 시스템 평가에\\n자금을 지원할 계획'),\n",
       " Document(id='770c945c-1e81-42f1-8e92-33bbede798a2', metadata={'source': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 9, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='Forum and over $10 million for a new AI Safety Fund, 2023.10.25.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result = pdf_retriever.invoke(\"엔스로픽에 투자한 기업과 투자금액을 알려주세요.\")\n",
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e004d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 구글(Google): 최대 20억 달러 투자 합의; 우선 5억 달러 투자, 향후 15억 달러 추가 투자 예정; 2023년 2월에 이미 5억 5,000만 달러 투자.\n",
      "- 아마존(Amazon): 최대 40억 달러의 투자 계획 발표(2023년 9월).\n",
      "\n",
      "Source\n",
      "- SPRI_AI_Brief_2023년12월호_F.pdf (page 13)\n"
     ]
    }
   ],
   "source": [
    "answer = pdf_chain.invoke(\n",
    "    {\n",
    "        \"question\":\"엔스로픽에 투자한 기업과 투자금액을 알려주세요.\",\n",
    "        \"context\":search_result,\n",
    "        \"chat_history\":[],\n",
    "    }\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f0eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State 정의\n",
    "from typing import Annotated, TypedDict, List\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 노드에서 다른 노드로 전달할 때 알려줄 State (상태결과)\n",
    "class MyState(TypedDict):\n",
    "    question: Annotated[str, \"Question\"]        # 질문\n",
    "    context: Annotated[str, \"Context\"]          # 문서 검색 결과\n",
    "    answer: Annotated[str, \"Answer\"]            # 답변\n",
    "    messages: Annotated[list, add_messages]         # 메시지 누적 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f58d44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 정의 (리트리브 노드, LLM 노드)\n",
    "from langchain_teddynote.messages import messages_to_history\n",
    "from rag.utils import format_docs\n",
    "\n",
    "# 문서 검색 노드\n",
    "def retrieve_document(state : MyState) -> MyState:\n",
    "    # 마지막 질문\n",
    "    latest_question = state[\"question\"]\n",
    "    # 문서에서 유사도 검색\n",
    "    retrieved_docs = pdf_retriever.invoke(latest_question)\n",
    "    retrieved_docs = format_docs(retrieved_docs)\n",
    "    return MyState(context=retrieved_docs)\n",
    "\n",
    "# LLM 답변 노드\n",
    "def llm_answer(state : MyState)->MyState:\n",
    "    # 질문을 상태에서 가져온다\n",
    "    latest_question = state[\"question\"]\n",
    "    # 검색된 문서를 상태에서 가져옵니다\n",
    "    context = state[\"context\"]\n",
    "    #체인을 호출하여 답변을 생성한다\n",
    "    response = pdf_chain.invoke({\n",
    "        \"question\" : latest_question,\n",
    "        \"context\": context,\n",
    "        \"chat_history\":messages_to_history(state[\"messages\"])\n",
    "    })\n",
    "    return MyState(answer=response, messages=[(\"user\", latest_question), (\"assistant\", response)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11854164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태그래프에 Node 추가 -> Edge로 연결 -> 상태그래프 컴파일\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 상태그래프 생성\n",
    "workflow = StateGraph(MyState)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"retrieve\", retrieve_document)\n",
    "workflow.add_node(\"llm_answer\", llm_answer)\n",
    "\n",
    "# 엣지로 연결\n",
    "workflow.add_edge(\"retrieve\", \"llm_answer\")\n",
    "workflow.add_edge(\"llm_answer\", END)\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "# 컴파일\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48564712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDGE = C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Chromium download.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browser OK: Edg/139.0.3405.125\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Chromium downloadable not found at https://storage.googleapis.com/chromium-browser-snapshots/Win_x64/1181205/chrome-win.zip: Received <?xml version='1.0' encoding='UTF-8'?><Error><Code>NoSuchKey</Code><Message>The specified key does not exist.</Message><Details>No such object: chromium-browser-snapshots/Win_x64/1181205/chrome-win.zip</Details></Error>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, Image\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MermaidDrawMethod\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m png = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMermaidDrawMethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPYPPETEER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m display(Image(data=png))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:695\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[39m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[32m    689\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    690\u001b[39m     curve_style=curve_style,\n\u001b[32m    691\u001b[39m     node_colors=node_colors,\n\u001b[32m    692\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    693\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    694\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:288\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m draw_method == MermaidDrawMethod.PYPPETEER:\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     img_bytes = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_render_mermaid_using_pyppeteer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m    294\u001b[39m     img_bytes = _render_mermaid_using_api(\n\u001b[32m    295\u001b[39m         mermaid_syntax,\n\u001b[32m    296\u001b[39m         output_file_path=output_file_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m    299\u001b[39m         retry_delay=retry_delay,\n\u001b[32m    300\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\asyncio\\futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\asyncio\\tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:326\u001b[39m, in \u001b[36m_render_mermaid_using_pyppeteer\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, padding, device_scale_factor)\u001b[39m\n\u001b[32m    323\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInstall Pyppeteer to use the Pyppeteer method: `pip install pyppeteer`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m browser = \u001b[38;5;28;01mawait\u001b[39;00m launch()\n\u001b[32m    327\u001b[39m page = \u001b[38;5;28;01mawait\u001b[39;00m browser.newPage()\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# Setup Mermaid JS\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\pyppeteer\\launcher.py:307\u001b[39m, in \u001b[36mlaunch\u001b[39m\u001b[34m(options, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlaunch\u001b[39m(options: \u001b[38;5;28mdict\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any) -> Browser:\n\u001b[32m    240\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Start chrome process and return :class:`~pyppeteer.browser.Browser`.\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[33;03m    This function is a shortcut to :meth:`Launcher(options, **kwargs).launch`.\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[33;03m    Available options are:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    305\u001b[39m \u001b[33;03m        option with extreme caution.\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mLauncher\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.launch()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\pyppeteer\\launcher.py:120\u001b[39m, in \u001b[36mLauncher.__init__\u001b[39m\u001b[34m(self, options, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chromeExecutable:\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_chromium():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[43mdownload_chromium\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28mself\u001b[39m.chromeExecutable = \u001b[38;5;28mstr\u001b[39m(chromium_executable())\n\u001b[32m    123\u001b[39m \u001b[38;5;28mself\u001b[39m.cmd = [\u001b[38;5;28mself\u001b[39m.chromeExecutable] + \u001b[38;5;28mself\u001b[39m.chromeArguments\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\pyppeteer\\chromium_downloader.py:138\u001b[39m, in \u001b[36mdownload_chromium\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_chromium\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    137\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Download and extract chromium.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     extract_zip(\u001b[43mdownload_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, DOWNLOADS_FOLDER / REVISION)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python312\\Lib\\site-packages\\pyppeteer\\chromium_downloader.py:82\u001b[39m, in \u001b[36mdownload_zip\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     80\u001b[39m r = http.request(\u001b[33m'\u001b[39m\u001b[33mGET\u001b[39m\u001b[33m'\u001b[39m, url, preload_content=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r.status >= \u001b[32m400\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mChromium downloadable not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mReceived \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.data.decode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# 10 * 1024\u001b[39;00m\n\u001b[32m     85\u001b[39m _data = BytesIO()\n",
      "\u001b[31mOSError\u001b[39m: Chromium downloadable not found at https://storage.googleapis.com/chromium-browser-snapshots/Win_x64/1181205/chrome-win.zip: Received <?xml version='1.0' encoding='UTF-8'?><Error><Code>NoSuchKey</Code><Message>The specified key does not exist.</Message><Details>No such object: chromium-browser-snapshots/Win_x64/1181205/chrome-win.zip</Details></Error>.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7fb381f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mretrieve\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mcontext\u001b[0m:\n",
      "<document><content>1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화\n",
      "KEY Contents\n",
      "n 구글이 앤스로픽에 최대 20억 달러 투자에 합의하고 5억 달러를 우선 투자했으며, 앤스로픽은\n",
      "구글과 클라우드 서비스 사용 계약도 체결\n",
      "n 3대 클라우드 사업자인 구글, 마이크로소프트, 아마존은 차세대 AI 모델의 대표 기업인\n",
      "앤스로픽 및 오픈AI와 협력을 확대하는 추세\n",
      "£구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공</content><source>SPRI_AI_Brief_2023년12월호_F.pdf</source><page>14</page></document>\n",
      "<document><content>4년간 30억 달러 규모의 계약을 체결\n",
      "∙ 오픈AI 창업자 그룹의 일원이었던 다리오(Dario Amodei)와 다니엘라 아모데이(Daniela Amodei)\n",
      "남매가 2021년 설립한 앤스로픽은 챗GPT의 대항마 ‘클로드(Claude)’ LLM을 개발\n",
      "n 아마존과 구글의 앤스로픽 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인 오픈\n",
      "AI와 협력을 확대\n",
      "∙ 마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 더해 2023년 1월 추가로 100억 달러를</content><source>SPRI_AI_Brief_2023년12월호_F.pdf</source><page>14</page></document>\n",
      "<document><content>£구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\n",
      "n 구글이 2023년 10월 27일 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 중 5억\n",
      "달러를 우선 투자하고 향후 15억 달러를 추가로 투자할 방침\n",
      "∙ 구글은 2023년 2월 앤스로픽에 이미 5억 5,000만 달러를 투자한 바 있으며, 아마존도 지난 9월\n",
      "앤스로픽에 최대 40억 달러의 투자 계획을 공개\n",
      "∙ 한편, 2023년 11월 8일 블룸버그 보도에 따르면 앤스로픽은 구글의 클라우드 서비스 사용을 위해\n",
      "4년간 30억 달러 규모의 계약을 체결</content><source>SPRI_AI_Brief_2023년12월호_F.pdf</source><page>14</page></document>\n",
      "<document><content>투자하기로 하면서 오픈AI의 지분 49%를 확보했으며, 오픈AI는 마이크로소프트의 애저(Azure)\n",
      "클라우드 플랫폼을 사용해 AI 모델을 훈련\n",
      "£구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\n",
      "n 구글은 수익률이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를\n",
      "통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자를 지속\n",
      "∙ 구글은 앤스로픽 외에도 AI 동영상 제작 도구를 개발하는 런웨이(Runway)와 오픈소스 소프트웨어\n",
      "기업 허깅 페이스(Hugging Face)에도 투자</content><source>SPRI_AI_Brief_2023년12월호_F.pdf</source><page>14</page></document>\n",
      "<document><content>2. 기업/산업\n",
      "▹ 미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성································7\n",
      "▹ 코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개 ·······································8\n",
      "▹ 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································9</content><source>SPRI_AI_Brief_2023년12월호_F.pdf</source><page>2</page></document>\n",
      "<document><content>1,000만 달러 이상을 기부\n",
      "∙ 또한 신기술의 거버넌스와 안전 분야에서 전문성을 갖춘 브루킹스 연구소 출신의 크리스 메서롤(Chris\n",
      "Meserole)을 포럼의 상무이사로 임명\n",
      "n 최근 AI 기술이 급속히 발전하면서 AI 안전에 관한 연구가 부족한 시점에, 포럼은 이러한 격차를 해소\n",
      "하기 위해 AI 안전 기금을 조성\n",
      "∙ 참여사들은 지난 7월 백악관 주재의 AI 안전 서약에서 외부자의 AI 시스템 취약점 발견과 신고를\n",
      "촉진하기로 약속했으며, 약속을 이행하기 위해 기금을 활용해 외부 연구집단의 AI 시스템 평가에\n",
      "자금을 지원할 계획</content><source>SPRI_AI_Brief_2023년12월호_F.pdf</source><page>10</page></document>\n",
      "<document><content>1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성\n",
      "KEY Contents\n",
      "n 구글, 앤스로픽, 마이크로소프트, 오픈AI가 참여하는 프런티어 모델 포럼이 자선단체와 함께 AI\n",
      "안전 연구를 위한 1,000만 달러 규모의 AI 안전 기금을 조성\n",
      "n 프런티어 모델 포럼은 AI 모델의 취약점을 발견하고 검증하는 레드팀 활동을 지원하기 위한\n",
      "모델 평가 기법 개발에 자금을 중점 지원할 계획</content><source>SPRI_AI_Brief_2023년12월호_F.pdf</source><page>10</page></document>\n",
      "<document><content>▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\n",
      "▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\n",
      "▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12</content><source>SPRI_AI_Brief_2023년12월호_F.pdf</source><page>2</page></document>\n",
      "<document><content>자금을 지원할 계획\n",
      "£AI 안전 기금으로 AI 레드팀을 위한 모델 평가 기법 개발을 중점 지원할 계획\n",
      "n 프런티어 모델 포럼은 AI 안전 기금을 통해 AI 레드팀 활동을 위한 새로운 모델 평가 기법의 개발을\n",
      "중점 지원할 예정\n",
      "∙ 포럼에 따르면 AI 레드팀에 대한 자금 지원은 AI 모델의 안전과 보안 기준의 개선과 함께 AI 시스템\n",
      "위험 대응 방안에 관한 산업계와 정부, 시민사회의 통찰력 확보에 도움이 될 전망으로, 포럼은 향후 몇\n",
      "달 안에 기금 지원을 위한 제안 요청을 받을 계획</content><source>SPRI_AI_Brief_2023년12월호_F.pdf</source><page>10</page></document>\n",
      "<document><content>모델 평가 기법 개발에 자금을 중점 지원할 계획\n",
      "£프런티어 모델 포럼, 자선단체와 함께 AI 안전 연구를 위한 기금 조성\n",
      "n 구글, 앤스로픽, 마이크로소프트, 오픈AI가 출범한 프런티어 모델 포럼이 2023년 10월 25일 AI 안전\n",
      "연구를 위한 기금을 조성한다고 발표\n",
      "∙ 참여사들은 맥거번 재단(Patrick J. McGovern Foundation), 데이비드 앤 루실 패커드 재단(The\n",
      "David and Lucile Packard Foundation) 등의 자선단체와 함께 AI 안전 연구를 위한 기금에</content><source>SPRI_AI_Brief_2023년12월호_F.pdf</source><page>10</page></document>\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mllm_answer\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32manswer\u001b[0m:\n",
      "- 구글: 앤스로픽에 최대 20억 달러 투자 합의; 우선 투자 5억 달러, 2023년 2월에 이미 5억 5,000만 달러 투자.\n",
      "- 아마존: 앤스로픽에 최대 40억 달러 투자 계획 공개(2023년 9월).\n",
      "\n",
      "Source\n",
      "- SPRI_AI_Brief_2023년12월호_F.pdf (page 14)\n",
      "('user', '앤스로릭에 투자한 기업과 투자금액을 알려주세요')\n",
      "('assistant', '- 구글: 앤스로픽에 최대 20억 달러 투자 합의; 우선 투자 5억 달러, 2023년 2월에 이미 5억 5,000만 달러 투자.\\n- 아마존: 앤스로픽에 최대 40억 달러 투자 계획 공개(2023년 9월).\\n\\nSource\\n- SPRI_AI_Brief_2023년12월호_F.pdf (page 14)')\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 그래프 실행\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import invoke_graph, stream_graph, random_uuid\n",
    "\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\":random_uuid()})\n",
    "\n",
    "inputs = MyState(question=\"앤스로릭에 투자한 기업과 투자금액을 알려주세요\")\n",
    "\n",
    "invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "142dccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mllm_answer\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "- 구글: 앤스로픽에 최대 20억 달러 투자 합의; 우선 투자 5억 달러, 2023년 2월에 이미 5억 5,000만 달러 투자\n",
      "- 아마존: 앤스로픽에 최대 40억 달러 투자 계획 공개(2023년 9월)\n",
      "\n",
      "Source\n",
      "- SPRI_AI_Brief_2023년12월호_F.pdf (page 14)"
     ]
    }
   ],
   "source": [
    "stream_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec5c7b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 앤스로릭에 투자한 기업과 투자금액을 알려주세요\n",
      "============================================================\n",
      "Answer:\n",
      "- 구글: 앤스로픽에 최대 20억 달러 투자 합의; 우선 투자 5억 달러, 2023년 2월에 이미 5억 5,000만 달러 투자\n",
      "- 아마존: 앤스로픽에 최대 40억 달러 투자 계획 공개(2023년 9월)\n",
      "\n",
      "Source\n",
      "- SPRI_AI_Brief_2023년12월호_F.pdf (page 14)\n"
     ]
    }
   ],
   "source": [
    "outputs = app.get_state(config).values\n",
    "\n",
    "print(f'Question: {outputs[\"question\"]}')\n",
    "print(\"===\" * 20)\n",
    "print(f'Answer:\\n{outputs[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b0072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
